{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "TransE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI-_9pepE6_v",
        "colab_type": "code",
        "outputId": "67e68d18-2ff3-420c-dbe1-ff8e23af5425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MuUxgnHFbnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "3bcdce05-c938-4d9b-887b-1c06b7c93ee1"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from dask import delayed\n",
        "from torch.autograd import Variable\n",
        "from os.path import join\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp0wmljHEG0r",
        "colab_type": "text"
      },
      "source": [
        "Создаем класс нашего датасета. Реализуем в нем все необходимые нам методы\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toeDYm6lE6_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WN18_train:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self.pos_triplets = None\n",
        "        self.num_ent = None\n",
        "        self.num_rel = None\n",
        "        self.neg_triplets = None\n",
        "\n",
        "        # These structures match head+rel with tail and tail+rel with head\n",
        "        self.head_rel_to_tail = {}\n",
        "        self.tail_rel_to_head = {}\n",
        "        \n",
        "    def download_triplets(self):\n",
        "      \"\"\"\n",
        "      This method reads triplets from the file and creates data structures which \n",
        "      will contribute to making negative samples \n",
        "      \"\"\"\n",
        "        t = []\n",
        "        \n",
        "        with open(self.file_path, 'r') as f:\n",
        "            data = f.readlines()\n",
        "            for el in data:\n",
        "                t.append(el.split())\n",
        "                head, rel, tail = [int(el) for el in el.split()]\n",
        "                \n",
        "                # Fill the heads, rels and tails into the dictionary of dictionaries head_rel_to_tail\n",
        "                if head not in self.head_rel_to_tail.keys():\n",
        "                    self.head_rel_to_tail[head] = {rel: [tail]}\n",
        "                else:\n",
        "                    if rel not in self.head_rel_to_tail[head].keys():\n",
        "                        self.head_rel_to_tail[head][rel] = [tail]\n",
        "                    else:\n",
        "                        self.head_rel_to_tail[head][rel].append(tail)\n",
        "                        \n",
        "                # Fill the tails, rels and heads into the dictionary of dictionaries tail_rel_to_head\n",
        "                if tail not in self.tail_rel_to_head.keys():\n",
        "                    self.tail_rel_to_head[tail] = {rel: [head]}\n",
        "                else:\n",
        "                    if rel not in self.tail_rel_to_head[tail]:\n",
        "                        self.tail_rel_to_head[tail][rel] = [head]\n",
        "                    else:\n",
        "                        self.tail_rel_to_head[tail][rel].append(head)\n",
        "                \n",
        "                \n",
        "        self.pos_triplets = np.array(t, dtype=np.int)\n",
        "        self.num_ent, self.num_rel = self.pos_triplets.max(axis=0)[:2] + 1\n",
        "        \n",
        "    def generate_neg_triplets(self):\n",
        "        \"\"\"\n",
        "        This method generates negative triplet for each posotive triplet. \n",
        "        In a negative triplet we just replace either tail or head with prob = 0.5 \n",
        "        \"\"\"\n",
        "        n = []\n",
        "\n",
        "        for i in range(self.pos_triplets.shape[0]):\n",
        "            head, rel, tail = self.pos_triplets[i, :]\n",
        "\n",
        "            # Choose what to replace: tail or head \n",
        "            if np.random.rand(1) > 0.5:\n",
        "                # Choose the index of head at random\n",
        "                neg_head = np.random.uniform(0, self.num_ent)\n",
        "                # If the random head occurs with the pair tail and rel, \n",
        "                # we choose the random index again\n",
        "                while neg_head in self.tail_rel_to_head[tail][rel] or neg_head == head:\n",
        "                    neg_head = np.random.uniform(0, self.num_ent)\n",
        "                head = neg_head\n",
        "            \n",
        "            else:\n",
        "                # Choose the index of tail at random\n",
        "                neg_tail = np.random.uniform(0, self.num_ent)\n",
        "                # If the random head occurs with the pair tail and rel, \n",
        "                # we choose the random index again\n",
        "                while neg_tail in self.head_rel_to_tail[head][rel] or neg_tail == tail:\n",
        "                    neg_tail = np.random.uniform(0, self.num_ent)\n",
        "                tail = neg_tail\n",
        "                \n",
        "            n.append([head, rel, tail])\n",
        "            \n",
        "        self.neg_triplets = np.array(n, dtype=np.int)\n",
        "                    \n",
        "    def __getitem__(self, index):\n",
        "        return self.pos_triplets[index], self.neg_triplets[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.pos_triplets.shape[0]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR8q_F2QHKE-",
        "colab_type": "text"
      },
      "source": [
        "Это наша TransE модель. В ней мы создаем entity и relation ембеддинги и реализуем прямой проход.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7LbnyPE6__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch \n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, dataset, vector_length=150):\n",
        "        super(TransE, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.num_ent = self.dataset.num_ent\n",
        "        self.num_rel = self.dataset.num_rel\n",
        "        self.vector_length = vector_length\n",
        "        self.ent_emb = nn.Embedding(self.num_ent, self.vector_length).cuda()\n",
        "        self.rel_emb = nn.Embedding(self.num_rel, self.vector_length).cuda()\n",
        "        \n",
        "        \n",
        "    def forward(self, pos_triplet, neg_triplet):\n",
        "        # We put triplets on GPU\n",
        "        pos_triplet = pos_triplet.cuda()\n",
        "        neg_triplet = neg_triplet.cuda()\n",
        "\n",
        "        # Take embeddings which correspond to indexes in trilets  \n",
        "        pos_head_emb = self.ent_emb(pos_triplet[:, 0]).cuda()\n",
        "        pos_rel_emb = self.rel_emb(pos_triplet[:, 1]).cuda()\n",
        "        pos_tail_emb = self.ent_emb(pos_triplet[:, 2]).cuda()\n",
        "        \n",
        "        neg_head_emb = self.ent_emb(neg_triplet[:, 0]).cuda()\n",
        "        neg_rel_emb = self.rel_emb(neg_triplet[:, 1]).cuda()\n",
        "        neg_tail_emb = self.ent_emb(neg_triplet[:, 2]).cuda()\n",
        "        \n",
        "        # Calculate the score which is a L-2 norm \n",
        "        neg_score = torch.norm((neg_head_emb + neg_rel_emb - neg_tail_emb), 2, 1)\n",
        "        pos_score = torch.norm((pos_head_emb + pos_rel_emb - pos_tail_emb), 2, 1)\n",
        "\n",
        "        losses = torch.stack((pos_score, neg_score), dim=1)\n",
        "        \n",
        "        return losses \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9beODFiE7AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/model_transE-master/wn18/train.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJR5qFIPE7AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = WN18_train(path)\n",
        "a.download_triplets()\n",
        "a.generate_neg_triplets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrkf09WwE7AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TransE(a).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
        "train_loader = DataLoader(a, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z6HIsU-E7AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataset, train_loader, optimizer, num_epochs=10):\n",
        "    loss = nn.MarginRankingLoss(0.1).cuda()\n",
        "    y = Variable(torch.Tensor([-1])).cuda()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        loss_accum = 0\n",
        "        \n",
        "        for i_step, (pos_triplet, neg_triplet) in enumerate(train_loader):\n",
        "            prediction = model(pos_triplet, neg_triplet)\n",
        "            loss_value = loss(prediction[:, 0], prediction[:, 1], y).cuda()\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_accum += loss_value.item()\n",
        "            \n",
        "        average_loss = loss_accum / i_step\n",
        "        print(f'Epoch: {epoch}, loss: {average_loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdEwI6HpE7AP",
        "colab_type": "code",
        "outputId": "2ebeaf3b-ca38-46f8-8bca-a66f52bb1b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train(model, a, train_loader, optimizer)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 0.00023060381698013362\n",
            "Epoch: 1, loss: 0.0001502393564205128\n",
            "Epoch: 2, loss: 0.00012811400034207834\n",
            "Epoch: 3, loss: 0.00011845291407812572\n",
            "Epoch: 4, loss: 0.00010524566698296846\n",
            "Epoch: 5, loss: 9.198086905162528e-05\n",
            "Epoch: 6, loss: 7.882698163036173e-05\n",
            "Epoch: 7, loss: 6.505557203168109e-05\n",
            "Epoch: 8, loss: 5.558507224098185e-05\n",
            "Epoch: 9, loss: 4.043237946725269e-05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}