{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "TransE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI-_9pepE6_v",
        "colab_type": "code",
        "outputId": "4266a0f4-7832-4a17-e7de-4a5c6f814f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MuUxgnHFbnF",
        "colab_type": "code",
        "outputId": "1c48ed28-15a7-4365-c277-fd8f5e9d0035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from dask import delayed\n",
        "from torch.autograd import Variable\n",
        "from os.path import join"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp0wmljHEG0r",
        "colab_type": "text"
      },
      "source": [
        "Создаем класс нашего датасета. Реализуем в нем все необходимые нам методы\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toeDYm6lE6_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WN18_train:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self.pos_triplets = None\n",
        "        self.num_ent = None\n",
        "        self.num_rel = None\n",
        "        self.neg_triplets = None\n",
        "\n",
        "        # These structures match head+rel with tail and tail+rel with head\n",
        "        self.head_rel_to_tail = {}\n",
        "        self.tail_rel_to_head = {}\n",
        "        \n",
        "    def download_triplets(self):\n",
        "        \"\"\"\n",
        "        This method reads triplets from the file and creates data structures which \n",
        "        will contribute to making negative samples \n",
        "        \"\"\"\n",
        "        t = []\n",
        "        \n",
        "        with open(self.file_path, 'r') as f:\n",
        "            data = f.readlines()\n",
        "            for el in data:\n",
        "                t.append(el.split())\n",
        "                head, rel, tail = [int(el) for el in el.split()]\n",
        "                \n",
        "                # Fill the heads, rels and tails into the dictionary of dictionaries head_rel_to_tail\n",
        "                if head not in self.head_rel_to_tail.keys():\n",
        "                    self.head_rel_to_tail[head] = {rel: [tail]}\n",
        "                else:\n",
        "                    if rel not in self.head_rel_to_tail[head].keys():\n",
        "                        self.head_rel_to_tail[head][rel] = [tail]\n",
        "                    else:\n",
        "                        self.head_rel_to_tail[head][rel].append(tail)\n",
        "                        \n",
        "                # Fill the tails, rels and heads into the dictionary of dictionaries tail_rel_to_head\n",
        "                if tail not in self.tail_rel_to_head.keys():\n",
        "                    self.tail_rel_to_head[tail] = {rel: [head]}\n",
        "                else:\n",
        "                    if rel not in self.tail_rel_to_head[tail]:\n",
        "                        self.tail_rel_to_head[tail][rel] = [head]\n",
        "                    else:\n",
        "                        self.tail_rel_to_head[tail][rel].append(head)\n",
        "                \n",
        "                \n",
        "        self.pos_triplets = np.array(t, dtype=np.int)\n",
        "        self.num_ent, self.num_rel = self.pos_triplets.max(axis=0)[:2] + 1\n",
        "        \n",
        "    def generate_neg_triplets(self):\n",
        "        \"\"\"\n",
        "        This method generates negative triplet for each posotive triplet. \n",
        "        In a negative triplet we just replace either tail or head with prob = 0.5 \n",
        "        \"\"\"\n",
        "        n = []\n",
        "\n",
        "        for i in range(self.pos_triplets.shape[0]):\n",
        "            head, rel, tail = self.pos_triplets[i, :]\n",
        "\n",
        "            # Choose what to replace: tail or head \n",
        "            if np.random.rand(1) > 0.5:\n",
        "                # Choose the index of head at random\n",
        "                neg_head = np.random.uniform(0, self.num_ent)\n",
        "                # If the random head occurs with the pair tail and rel, \n",
        "                # we choose the random index again\n",
        "                while neg_head in self.tail_rel_to_head[tail][rel] or neg_head == head:\n",
        "                    neg_head = np.random.uniform(0, self.num_ent)\n",
        "                head = neg_head\n",
        "            \n",
        "            else:\n",
        "                # Choose the index of tail at random\n",
        "                neg_tail = np.random.uniform(0, self.num_ent)\n",
        "                # If the random head occurs with the pair tail and rel, \n",
        "                # we choose the random index again\n",
        "                while neg_tail in self.head_rel_to_tail[head][rel] or neg_tail == tail:\n",
        "                    neg_tail = np.random.uniform(0, self.num_ent)\n",
        "                tail = neg_tail\n",
        "                \n",
        "            n.append([head, rel, tail])\n",
        "            \n",
        "        self.neg_triplets = np.array(n, dtype=np.int)\n",
        "                    \n",
        "    def __getitem__(self, index):\n",
        "        return self.pos_triplets[index], self.neg_triplets[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.pos_triplets.shape[0]\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR8q_F2QHKE-",
        "colab_type": "text"
      },
      "source": [
        "Это наша TransE модель. В ней мы создаем entity и relation ембеддинги и реализуем прямой проход.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7LbnyPE6__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch \n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, dataset, vector_length=300):\n",
        "        super(TransE, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.num_ent = self.dataset.num_ent\n",
        "        self.num_rel = self.dataset.num_rel\n",
        "        self.vector_length = vector_length\n",
        "        self.ent_emb = nn.Embedding(self.num_ent, self.vector_length)\n",
        "        self.rel_emb = nn.Embedding(self.num_rel, self.vector_length)\n",
        "        \n",
        "        \n",
        "    def forward(self, pos_triplet, neg_triplet):\n",
        "        # We put triplets on GPU\n",
        "        pos_triplet = pos_triplet.cuda()\n",
        "        neg_triplet = neg_triplet.cuda()\n",
        "\n",
        "        # Take embeddings which correspond to indexes in trilets  \n",
        "        pos_head_emb = self.ent_emb(pos_triplet[:, 0]).cuda()\n",
        "        pos_rel_emb = self.rel_emb(pos_triplet[:, 1]).cuda()\n",
        "        pos_tail_emb = self.ent_emb(pos_triplet[:, 2]).cuda()\n",
        "        \n",
        "        neg_head_emb = self.ent_emb(neg_triplet[:, 0]).cuda()\n",
        "        neg_rel_emb = self.rel_emb(neg_triplet[:, 1]).cuda()\n",
        "        neg_tail_emb = self.ent_emb(neg_triplet[:, 2]).cuda()\n",
        "        \n",
        "        # Calculate the score which is a L-2 norm \n",
        "        neg_score = torch.norm((neg_head_emb + neg_rel_emb - neg_tail_emb), 2, 1)\n",
        "        pos_score = torch.norm((pos_head_emb + pos_rel_emb - pos_tail_emb), 2, 1)\n",
        "\n",
        "        losses = torch.stack((pos_score, neg_score), dim=1)\n",
        "        \n",
        "        return losses   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLwx9WuVgji6",
        "colab_type": "text"
      },
      "source": [
        "Это класс для проверки перформанса нашей модели. Как итог, этот класс рассчитывает MRR. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI5UCKZ_deTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class validation:\n",
        "    def __init__(self, file_path, ent_emb, rel_emb):\n",
        "        self.file_path = file_path \n",
        "        self.ent_emb = ent_emb\n",
        "        self.rel_emb = rel_emb\n",
        "        self.y_indices = None\n",
        "        self.prediction = None\n",
        "        self.similarity = None\n",
        "        self.y = None\n",
        "        self.mrr = None\n",
        "\n",
        "    def generate_prediction(self):\n",
        "        \"\"\" \n",
        "        Make the prediction based in validation data and stores the desired \n",
        "        prediction. \n",
        "        \"\"\"\n",
        "        b = []\n",
        "        with open(self.file_path, 'r') as f:\n",
        "            data = f.readlines()\n",
        "            for el in data:\n",
        "                b.append([int(a) for a in el.split()])\n",
        "\n",
        "        b = np.array(b)\n",
        "\n",
        "        # Store the prediction, the embedding of the desired y and index of desired y\n",
        "        self.prediction = torch.stack([self.ent_emb[b[i, 0]] + self.rel_emb[b[i, 1]] for i in range(b.shape[0])], dim=0)\n",
        "        self.y = torch.stack([self.ent_emb[b[i, 2]] for i in range(b.shape[0])], dim=0)\n",
        "        self.y_indices = b[:, 2]\n",
        "\n",
        "    def generate_similarity(self):\n",
        "        \"\"\"\n",
        "        We create the self.similariry matrix, which contains the cosine \n",
        "        similarities. Each row represents the predicted vector, and column\n",
        "        shows the similariry between this vector and embedding[column]. \n",
        "        We need it to calculate MRR. \n",
        "        \"\"\"\n",
        "        n = self.y.shape[0]\n",
        "        m = self.ent_emb.shape[0]\n",
        "\n",
        "        # Calculate the similarities matrix\n",
        "        dot_products = torch.matmul(self.prediction, self.ent_emb.t())\n",
        "\n",
        "        lengths_pred = torch.matmul(self.prediction, self.prediction.t())[range(n), range(n)]\n",
        "        lengths_pred = torch.sqrt(lengths_pred).view(-1, 1)\n",
        "\n",
        "        lengths_y = torch.matmul(self.ent_emb, self.ent_emb.t())[range(m), range(m)]\n",
        "        lengths_y = torch.sqrt(lengths_y).view(1, -1)\n",
        "\n",
        "        self.similarity = dot_products / (lengths_pred * lengths_y)\n",
        "\n",
        "        # Sort the similariry matrix. We want to see how many vectors are \n",
        "        # more similar to a target vector than the supposed one. The fewer the better  \n",
        "        ordered, indices = self.similarity.sort(dim=1, descending=True)\n",
        "\n",
        "        l = torch.stack([torch.nonzero(indices[i] == self.y_indices[i]) for i in range(self.y_indices.shape[0])], dim=0).view(-1).float() + 1\n",
        "        l = 1 / l\n",
        "        self.mrr = torch.mean(l)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9beODFiE7AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/model_transE-master/wn18/train.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJR5qFIPE7AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = WN18_train(path)\n",
        "a.download_triplets()\n",
        "a.generate_neg_triplets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrkf09WwE7AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TransE(a).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0)\n",
        "train_loader = DataLoader(a, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z6HIsU-E7AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataset, train_loader, optimizer, num_epochs=40, margin=5):\n",
        "    loss = nn.MarginRankingLoss(margin).cuda()\n",
        "    y = Variable(torch.Tensor([-1])).cuda()\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        model.train()\n",
        "        loss_accum = 0\n",
        "        \n",
        "        for i_step, (pos_triplet, neg_triplet) in enumerate(train_loader):\n",
        "            prediction = model(pos_triplet, neg_triplet)\n",
        "            loss_value = loss(prediction[:, 0], prediction[:, 1], y).cuda()\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_accum += loss_value.item()\n",
        "            \n",
        "    # if epoch % val_every == 0:\n",
        "    #     print(\"Performing validation.....\")\n",
        "    #     ent_emb, rel_emb = model.parameters()\n",
        "    #     ent_emb = ent_emb.to(\"cpu\")\n",
        "    #     rel_emb = rel_emb.to(\"cpu\")\n",
        "\n",
        "    #     valid_path = '/content/drive/My Drive/model_transE-master/wn18/valid.txt'\n",
        "\n",
        "    #     v = validation(valid_path, ent_emb, rel_emb)\n",
        "    #     v.generate_prediction()\n",
        "    #     v.generate_similarity()\n",
        "    #     print(v.mrr)\n",
        "\n",
        "        average_loss = loss_accum / i_step\n",
        "        print(f'Epoch: {epoch}, loss: {average_loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdEwI6HpE7AP",
        "colab_type": "code",
        "outputId": "6dbd4369-5be0-4950-d5b8-9dbd617c0302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "train(model, a, train_loader, optimizer, num_epochs=40, margin=15)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 14.201415748941413\n",
            "Epoch: 2, loss: 10.858612067451304\n",
            "Epoch: 3, loss: 7.897460328184102\n",
            "Epoch: 4, loss: 5.5077528202695545\n",
            "Epoch: 5, loss: 3.784234319013708\n",
            "Epoch: 6, loss: 2.573308495914235\n",
            "Epoch: 7, loss: 1.7133325825449568\n",
            "Epoch: 8, loss: 1.1051314752835495\n",
            "Epoch: 9, loss: 0.6810341488991388\n",
            "Epoch: 10, loss: 0.40049869904960445\n",
            "Epoch: 11, loss: 0.22281927262091528\n",
            "Epoch: 12, loss: 0.1188880741731074\n",
            "Epoch: 13, loss: 0.06224026698197714\n",
            "Epoch: 14, loss: 0.03272085758895356\n",
            "Epoch: 15, loss: 0.018373072208052846\n",
            "Epoch: 16, loss: 0.010328764808933119\n",
            "Epoch: 17, loss: 0.007059221306807315\n",
            "Epoch: 18, loss: 0.0045647915267297045\n",
            "Epoch: 19, loss: 0.003363843983654523\n",
            "Epoch: 20, loss: 0.002614208253530356\n",
            "Epoch: 21, loss: 0.001870625557133515\n",
            "Epoch: 22, loss: 0.001821123636685885\n",
            "Epoch: 23, loss: 0.001849787206941061\n",
            "Epoch: 24, loss: 0.0014867544443898611\n",
            "Epoch: 25, loss: 0.0014869474784820868\n",
            "Epoch: 26, loss: 0.0011650566466793217\n",
            "Epoch: 27, loss: 0.0009984758577195768\n",
            "Epoch: 28, loss: 0.00111667047933216\n",
            "Epoch: 29, loss: 0.000887028893194587\n",
            "Epoch: 30, loss: 0.0008741846788522885\n",
            "Epoch: 31, loss: 0.0006538790005903977\n",
            "Epoch: 32, loss: 0.000620694600079394\n",
            "Epoch: 33, loss: 0.0006700405640300043\n",
            "Epoch: 34, loss: 0.0006543210863527669\n",
            "Epoch: 35, loss: 0.0005973746738822212\n",
            "Epoch: 36, loss: 0.0004233444842817557\n",
            "Epoch: 37, loss: 0.0005892314050532035\n",
            "Epoch: 38, loss: 0.00047794463138235103\n",
            "Epoch: 39, loss: 0.0004248898897775158\n",
            "Epoch: 40, loss: 0.00045643005840379186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L66VP1E1_XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ent_emb, rel_emb = model.parameters()\n",
        "ent_emb = ent_emb.to(\"cpu\")\n",
        "rel_emb = rel_emb.to(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgoDdwE13SXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_path = '/content/drive/My Drive/model_transE-master/wn18/valid.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi0_PD04cVv3",
        "colab_type": "code",
        "outputId": "305dea0d-37d9-4f74-b197-fb9c2767785b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = validation(valid_path, ent_emb, rel_emb)\n",
        "v.generate_prediction()\n",
        "v.generate_similarity()\n",
        "print(v.mrr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1885)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}